{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "from math import radians\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "import torch\n",
    "from torch.utils.dlpack import to_dlpack, from_dlpack\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_undirected, is_undirected, convert\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "#from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "pd.options.mode.chained_assignment = None\n",
    "from dgl import DGLGraph\n",
    "import time\n",
    "\n",
    "def MAPELoss(output, target):\n",
    "    return torch.mean(torch.abs((target - output) / target))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>train_mask</th>\n",
       "      <th>val_mask</th>\n",
       "      <th>test_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h1</td>\n",
       "      <td>12.9716</td>\n",
       "      <td>77.5946</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1200</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h2</td>\n",
       "      <td>19.0760</td>\n",
       "      <td>72.8770</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h3</td>\n",
       "      <td>28.7041</td>\n",
       "      <td>77.1025</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h4</td>\n",
       "      <td>22.5726</td>\n",
       "      <td>80.6390</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>1780</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h5</td>\n",
       "      <td>13.0827</td>\n",
       "      <td>80.2707</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>1450</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h6</td>\n",
       "      <td>23.2599</td>\n",
       "      <td>77.4126</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>3000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t1</td>\n",
       "      <td>12.9713</td>\n",
       "      <td>77.5920</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1300</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t2</td>\n",
       "      <td>19.0030</td>\n",
       "      <td>72.8605</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3</td>\n",
       "      <td>28.7048</td>\n",
       "      <td>77.2000</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  house      lat      lon  x1  x2     y  train_mask  val_mask  test_mask\n",
       "0    h1  12.9716  77.5946  20   5  1200        True     False      False\n",
       "1    h2  19.0760  72.8770  35   5  1500        True     False      False\n",
       "2    h3  28.7041  77.1025  24   7  2000        True     False      False\n",
       "3    h4  22.5726  80.6390  33  13  1780        True     False      False\n",
       "4    h5  13.0827  80.2707  35  16  1450        True     False      False\n",
       "5    h6  23.2599  77.4126  18  21  3000        True     False      False\n",
       "6    t1  12.9713  77.5920  19   6  1300       False      True      False\n",
       "7    t2  19.0030  72.8605  32   6  1600       False      True      False\n",
       "8    t3  28.7048  77.2000  23   6  1800       False     False       True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.DataFrame({\n",
    "    'house':['h1','h2','h3','h4','h5','h6','t1','t2','t3'],\n",
    "    'lat':[12.9716,19.076,28.7041,22.5726,13.0827,23.2599,12.9713,19.003,28.7048],\n",
    "    'lon':[77.5946,72.877,77.1025,80.639,80.2707,77.4126,77.5920,72.8605,77.2000],\n",
    "    'x1':[20,35,24,33,35,18,19,32,23],\n",
    "    'x2':[5,5,7,13,16,21,6,6,6],\n",
    "    'y':[1200,1500,2000,1780,1450,3000,1300,1600,1800],\n",
    "    'train_mask':[True,True,True,True,True,True,False,False,False],\n",
    "    'val_mask':[False,False,False,False,False,False,True,True,False],\n",
    "    'test_mask':[False,False,False,False,False,False,False,False,True]})\n",
    "cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_transform(df, m):\n",
    "    df['lat'] = np.radians(df['lat'])\n",
    "    df['lon'] = np.radians(df['lon'])\n",
    "    \n",
    "    dist = DistanceMetric.get_metric('haversine')\n",
    "    \n",
    "    df_dist = pd.DataFrame(dist.pairwise(df[['lat','lon']].to_numpy())*6373,  columns=df.house.unique(), index=df.house.unique())\n",
    "    \n",
    "    D = df_dist.values\n",
    "    D[D < m] = 1\n",
    "    D[D >= m] = 0\n",
    "    \n",
    "    G = nx.from_numpy_matrix(D)\n",
    "    edge_index = from_networkx(G).edge_index\n",
    "    \n",
    "    x = torch.tensor(df[['x1','x2']].values, dtype=torch.float)\n",
    "    y = torch.tensor(df[['y']].values, dtype=torch.float)\n",
    "    train_mask = torch.BoolTensor(df[['train_mask']].values)\n",
    "    val_mask = torch.BoolTensor(df[['val_mask']].values)\n",
    "    test_mask = torch.BoolTensor(df[['test_mask']].values)\n",
    "    \n",
    "    data = Data(x=x, y=y, edge_index=edge_index)\n",
    "    \n",
    "    g = DGLGraph(nx.from_numpy_matrix(D))\n",
    "    features = x\n",
    "    labels = y\n",
    "    \n",
    "    return edge_index, g, features, labels, train_mask, val_mask, test_mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shao/anaconda3/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "edge_index, g, features, labels, train_mask, val_mask, test_mask   = geo_transform(cities_df, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6,\n",
       "         6, 6, 7, 7, 7, 8, 8, 8, 8],\n",
       "        [0, 4, 6, 1, 5, 7, 2, 3, 5, 8, 2, 3, 5, 8, 0, 4, 6, 1, 2, 3, 5, 7, 8, 0,\n",
       "         4, 6, 1, 5, 7, 2, 3, 5, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=9, num_edges=33,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        self.z = edges.src['z']\n",
    "        self.e = edges.data['e']\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        self.alpha = alpha\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        self.h = h\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')\n",
    "\n",
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))\n",
    "        \n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# # create the model, 2 heads, each head has hidden size 8\n",
    "# net = GAT(g,\n",
    "#           in_dim=features.size()[1],\n",
    "#           hidden_dim=8,\n",
    "#           out_dim=1,\n",
    "#           num_heads=2)\n",
    "\n",
    "# # create optimizer\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-1)\n",
    "\n",
    "# # main loop\n",
    "# dur = []\n",
    "# for epoch in range(10):\n",
    "#     if epoch >= 3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     logits = net(features)\n",
    "#     loss = MAPELoss(logits[mask], labels[mask])\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if epoch >= 3:\n",
    "#         dur.append(time.time() - t0)\n",
    "\n",
    "#     print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}\".format(\n",
    "#         epoch, loss.item(), np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (layer1): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=2, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (1): GATLayer(\n",
      "        (fc): Linear(in_features=2, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "        (attn_fc): Linear(in_features=2, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Epoch 00000 | Time(s) nan | Loss 0.9951 | TrainLoss 0.9951 | ValLoss 0.9946 | ETputs(KTEPS) nan\n",
      "Epoch 00001 | Time(s) nan | Loss 0.9841 | TrainLoss 0.9841 | ValLoss 0.9807 | ETputs(KTEPS) nan\n",
      "Epoch 00002 | Time(s) nan | Loss 0.9724 | TrainLoss 0.9724 | ValLoss 0.9670 | ETputs(KTEPS) nan\n",
      "Epoch 00003 | Time(s) 0.0076 | Loss 0.9594 | TrainLoss 0.9594 | ValLoss 0.9517 | ETputs(KTEPS) 4.35\n",
      "Epoch 00004 | Time(s) 0.0080 | Loss 0.9445 | TrainLoss 0.9445 | ValLoss 0.9341 | ETputs(KTEPS) 4.11\n",
      "Epoch 00005 | Time(s) 0.0090 | Loss 0.9268 | TrainLoss 0.9268 | ValLoss 0.9129 | ETputs(KTEPS) 3.66\n",
      "Epoch 00006 | Time(s) 0.0084 | Loss 0.9058 | TrainLoss 0.9058 | ValLoss 0.8877 | ETputs(KTEPS) 3.91\n",
      "Epoch 00007 | Time(s) 0.0081 | Loss 0.8812 | TrainLoss 0.8812 | ValLoss 0.8586 | ETputs(KTEPS) 4.10\n",
      "Epoch 00008 | Time(s) 0.0078 | Loss 0.8464 | TrainLoss 0.8464 | ValLoss 0.8192 | ETputs(KTEPS) 4.23\n",
      "Epoch 00009 | Time(s) 0.0078 | Loss 0.8136 | TrainLoss 0.8136 | ValLoss 0.7808 | ETputs(KTEPS) 4.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shao/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/shao/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, loss, model):\n",
    "        score = loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score > self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "        return self.early_stop\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), 'es_checkpoint.pt')\n",
    "\n",
    "\n",
    "\n",
    "# create the model, 2 heads, each head has hidden size 8\n",
    "net = GAT(g,\n",
    "          in_dim=features.size()[1],\n",
    "          hidden_dim=8,\n",
    "          out_dim=1,\n",
    "          num_heads=2)        \n",
    "        \n",
    "print(net)\n",
    "stopper = EarlyStopping(patience=100)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-1)     \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# initialize graph\n",
    "dur = []\n",
    "for epoch in range(10):\n",
    "    net.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    # forward\n",
    "    logits = net(features)\n",
    "    loss = MAPELoss(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    train_loss = MAPELoss(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    val_loss = MAPELoss(logits[val_mask], labels[val_mask])\n",
    "    if stopper.step(val_loss, net):\n",
    "        break\n",
    "\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | TrainLoss {:.4f} |\"\n",
    "          \" ValLoss {:.4f} | ETputs(KTEPS) {:.2f}\".\n",
    "          format(epoch, np.mean(dur), loss.item(), train_loss,\n",
    "                 val_loss, g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def preprocess_attention(edge_atten, g, to_normalize=True):\n",
    "    \"\"\"Organize attentions in the form of csr sparse adjacency\n",
    "    matrices from attention on edges. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_atten : numpy.array of shape (# edges, # heads, 1)\n",
    "        Un-normalized attention on edges.\n",
    "    g : dgl.DGLGraph.\n",
    "    to_normalize : bool\n",
    "        Whether to normalize attention values over incoming\n",
    "        edges for each node.\n",
    "    \"\"\"\n",
    "    n_nodes = g.number_of_nodes()\n",
    "    num_heads = edge_atten.shape[1]\n",
    "    all_head_A = [lil_matrix((n_nodes, n_nodes)) for _ in range(num_heads)]\n",
    "    for i in range(n_nodes):\n",
    "        predecessors = list(g.predecessors(i))\n",
    "        edges_id = g.edge_ids(predecessors, i)\n",
    "        for j in range(num_heads):\n",
    "            all_head_A[j][i, predecessors] = edge_atten[edges_id, j].data.cpu().numpy()\n",
    "            #all_head_A[j][i, predecessors] = edge_atten[edges_id, j, 0].data.cpu().numpy()\n",
    "    if to_normalize:\n",
    "        for j in range(num_heads):\n",
    "            all_head_A[j] = normalize(all_head_A[j], norm='l1').tocsr()\n",
    "    return all_head_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = g.edata['e']     \n",
    "A = preprocess_attention(A, g) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3333333333333333\n",
      "  (0, 4)\t0.3333333333333333\n",
      "  (0, 6)\t0.3333333333333333\n",
      "  (1, 1)\t0.3221031918534302\n",
      "  (1, 5)\t0.35579361629313955\n",
      "  (1, 7)\t0.3221031918534302\n",
      "  (2, 2)\t0.24952355068327076\n",
      "  (2, 3)\t0.24952355068327076\n",
      "  (2, 5)\t0.25142934795018773\n",
      "  (2, 8)\t0.24952355068327076\n",
      "  (3, 2)\t0.24952355068327076\n",
      "  (3, 3)\t0.24952355068327076\n",
      "  (3, 5)\t0.25142934795018773\n",
      "  (3, 8)\t0.24952355068327076\n",
      "  (4, 0)\t0.3333333333333333\n",
      "  (4, 4)\t0.3333333333333333\n",
      "  (4, 6)\t0.3333333333333333\n",
      "  (5, 1)\t0.15654216128312695\n",
      "  (5, 2)\t0.17140194723605384\n",
      "  (5, 3)\t0.17140194723605384\n",
      "  (5, 5)\t0.17270983572558452\n",
      "  (5, 7)\t0.15654216128312695\n",
      "  (5, 8)\t0.17140194723605384\n",
      "  (6, 0)\t0.3333333333333333\n",
      "  (6, 4)\t0.3333333333333333\n",
      "  (6, 6)\t0.3333333333333333\n",
      "  (7, 1)\t0.3221031918534302\n",
      "  (7, 5)\t0.35579361629313955\n",
      "  (7, 7)\t0.3221031918534302\n",
      "  (8, 2)\t0.24952355068327076\n",
      "  (8, 3)\t0.24952355068327076\n",
      "  (8, 5)\t0.25142934795018773\n",
      "  (8, 8)\t0.24952355068327076\n"
     ]
    }
   ],
   "source": [
    "print(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6,\n",
       "         6, 6, 7, 7, 7, 8, 8, 8, 8],\n",
       "        [0, 4, 6, 1, 5, 7, 2, 3, 5, 8, 2, 3, 5, 8, 0, 4, 6, 1, 2, 3, 5, 7, 8, 0,\n",
       "         4, 6, 1, 5, 7, 2, 3, 5, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
